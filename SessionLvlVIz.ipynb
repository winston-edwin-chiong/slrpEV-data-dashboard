{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "092882a5-2bf2-4b69-ac42-0b7e845850c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.pipeline import Pipeline\n",
    "import plotly.express as px\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c4f9ca4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class SortDropCast(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    This pipeline step will sort values by field \"connectTime\",\n",
    "    drop columns \"user_email\", \"slrpPaymentId\", \n",
    "    and cast columns \"cumEnergy_Wh\", \"peakPower_W\" as float values. \n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def transform(X) -> pd.DataFrame:\n",
    "        X = X.sort_values(by=\"connectTime\").drop(\n",
    "            columns=[\"user_email\", \"slrpPaymentId\"]).reset_index(drop=True)\n",
    "        X[\"cumEnergy_Wh\"] = X[\"cumEnergy_Wh\"].astype(float)\n",
    "        X[\"peakPower_W\"] = X[\"peakPower_W\"].astype(float)\n",
    "        return X\n",
    "\n",
    "\n",
    "class HelperFeatureCreation(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    This pipeline step will drop any records that contain 0 for \n",
    "    \"peakPower_W\" or \"cumEnergy_Wh\". Four additional columns will be created:\n",
    "    \"reqChargeTime\", \"finishChargeTime\", \"Overstay\", and \"Overstay_h\". \n",
    "    Any records with calculated charging durations greater than a day will be dropped. \n",
    "    Raw data (with these new features) at this staged will be saved.\n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    @classmethod\n",
    "    def transform(cls, X) -> pd.DataFrame:\n",
    "        X = X.loc[(X[\"peakPower_W\"] != 0) & (\n",
    "            X[\"cumEnergy_Wh\"] != 0)].copy(deep=True)\n",
    "\n",
    "        X[\"connectTime\"] = pd.to_datetime(X[\"connectTime\"])\n",
    "        X[\"startChargeTime\"] = pd.to_datetime(X[\"startChargeTime\"])\n",
    "        X[\"Deadline\"] = pd.to_datetime(X[\"Deadline\"])\n",
    "        X[\"lastUpdate\"] = pd.to_datetime(X[\"lastUpdate\"])\n",
    "\n",
    "        X[\"finishChargeTime\"] = X.apply(cls.__get_finishChargeTime, axis=1)\n",
    "        X[\"trueDurationHrs\"] = X.apply(cls.__get_duration, axis=1)\n",
    "        X[\"true_peakPower_W\"] = X[\"cumEnergy_Wh\"] / X[\"trueDurationHrs\"]\n",
    "\n",
    "        # filter out bad rows (this occurs when there is a very low peak power and high energy delivered)\n",
    "        X = X.loc[X[\"trueDurationHrs\"] <= 24].copy()\n",
    "\n",
    "        X['temp_0'] = pd.Timedelta(days=0, seconds=0)\n",
    "        X['Overstay'] = X[\"lastUpdate\"] - X['Deadline']\n",
    "        X[\"Overstay\"] = X[[\"Overstay\", \"temp_0\"]].max(axis=1)\n",
    "        X['Overstay_h'] = X['Overstay'].dt.seconds / 3600\n",
    "\n",
    "        X.drop(columns=['temp_0'], inplace=True)\n",
    "\n",
    "        X.to_csv(\"data/raw_data.csv\")\n",
    "\n",
    "        return X\n",
    "    \n",
    "    @staticmethod\n",
    "    def __get_duration(row):\n",
    "        if row[\"regular\"] == 1:\n",
    "            return round(((row[\"lastUpdate\"] - row[\"startChargeTime\"]).seconds/3600), 3)\n",
    "        else: \n",
    "            return round(((row[\"Deadline\"] - row[\"startChargeTime\"]).seconds/3600), 3)\n",
    "        \n",
    "    @staticmethod\n",
    "    def __get_finishChargeTime(row):\n",
    "        if row[\"regular\"] == 1:\n",
    "            return row[\"lastUpdate\"]\n",
    "        else:\n",
    "            return row[\"Deadline\"]\n",
    "        \n",
    "\n",
    "class CreateSessionTimeSeries(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    This pipeline step will create a time series for each session. A dataframe\n",
    "    with 5-min granularity will be returned, with one column, \"power_demand_W\".\n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X) -> pd.DataFrame:\n",
    "        self.rows = []\n",
    "        X.apply(self.__create_ts, axis=1)\n",
    "        X = pd.concat(self.rows, axis=0).sort_index()\n",
    "        X = X.resample(\"5MIN\").sum()\n",
    "        return X\n",
    "\n",
    "    def __create_ts(self, session):\n",
    "        \"\"\"\n",
    "        This helper function takes in a session, with a \"connectTime\", \"finishChargeTime\", and \n",
    "        a \"peakPower_W\" column. Function will return a time series at 5-min granularity. \n",
    "        \"\"\"\n",
    "        date_range = pd.date_range(\n",
    "            start=session[\"startChargeTime\"], end=session[\"finishChargeTime\"], freq=\"5min\")\n",
    "        temp_df = pd.DataFrame(index=date_range)\n",
    "        temp_df[\"avg_power_demand_W\"] = session[\"true_peakPower_W\"]  # rename\n",
    "        self.rows.append(temp_df)\n",
    "\n",
    "\n",
    "class FeatureCreation(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    This pipeline step will create an \"energy_demand_kWh\" and \"peak_power_W\" column. \n",
    "    The name of the dataframe's index will be set to \"time\", and \"day\" and \"month\" columns \n",
    "    will be created. \n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    @ staticmethod\n",
    "    def transform(X) -> pd.DataFrame:\n",
    "        X[\"energy_demand_kWh\"] = (X[\"avg_power_demand_W\"]/1000)/12\n",
    "        # for the highest granularity, peak power is equal to the power demand\n",
    "        # (different for different granularities though)\n",
    "        X[\"peak_power_W\"] = X[\"avg_power_demand_W\"]\n",
    "        X.index.name = \"time\"\n",
    "        X[\"day\"] = X.index.day_name()\n",
    "        X[\"month\"] = X.index.month_name()\n",
    "        return X\n",
    "\n",
    "\n",
    "class SaveToCsv(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    This pipeline step takes each dataframe and creates new granularities\n",
    "    (hourly, daily, and monthly). Each dataframe is saved to a \"data/\" file. \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.agg_key = {\n",
    "            \"avg_power_demand_W\": \"mean\",\n",
    "            \"energy_demand_kWh\": \"sum\",\n",
    "            \"peak_power_W\": \"max\",\n",
    "            \"day\": \"first\",\n",
    "            \"month\": \"first\"\n",
    "        }\n",
    "        self.dataframe_names = [\n",
    "            \"fivemindemand\",\n",
    "            \"hourlydemand\",\n",
    "            \"dailydemand\",\n",
    "            \"monthlydemand\"\n",
    "        ]\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X) -> dict:\n",
    "        # create new granularities\n",
    "        hourlydemand = X.resample(\"1H\").agg(self.agg_key)\n",
    "        dailydemand = X.resample(\"24H\").agg(self.agg_key)\n",
    "        monthlydemand = X.resample(\"1M\").agg(self.agg_key)\n",
    "\n",
    "        new_dataframes = {\n",
    "            \"fivemindemand\": X,\n",
    "            \"hourlydemand\": hourlydemand,\n",
    "            \"dailydemand\": dailydemand,\n",
    "            \"monthlydemand\": monthlydemand\n",
    "        }\n",
    "\n",
    "        # save to file system\n",
    "        for idx, dataframe in enumerate(new_dataframes.values()):\n",
    "            dataframe.to_csv(f\"data/{self.dataframe_names[idx]}.csv\")\n",
    "        return new_dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa45548a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "475dd3d8de922d6629668699edf7da91807dd0e731d2ca4abf0ed1b52cb8d54e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
