{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "092882a5-2bf2-4b69-ac42-0b7e845850c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.pipeline import Pipeline\n",
    "import plotly.express as px\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c4f9ca4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class SortDropCast(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    This pipeline step will sort values by field \"connectTime\",\n",
    "    drop columns \"user_email\", \"slrpPaymentId\", \n",
    "    and cast columns \"cumEnergy_Wh\", \"peakPower_W\" as float values. \n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def transform(X) -> pd.DataFrame:\n",
    "        X = X.sort_values(by=\"connectTime\").drop(\n",
    "            columns=[\"user_email\", \"slrpPaymentId\"]).reset_index(drop=True)\n",
    "        X[\"cumEnergy_Wh\"] = X[\"cumEnergy_Wh\"].astype(float)\n",
    "        X[\"peakPower_W\"] = X[\"peakPower_W\"].astype(float)\n",
    "        return X\n",
    "\n",
    "\n",
    "class HelperFeatureCreation(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    This pipeline step will drop any records that contain 0 for \n",
    "    \"peakPower_W\" or \"cumEnergy_Wh\". Four additional columns will be created:\n",
    "    \"reqChargeTime\", \"finishChargeTime\", \"Overstay\", and \"Overstay_h\". \n",
    "    Any records with calculated charging durations greater than a day will be dropped. \n",
    "    Raw data (with these new features) at this staged will be saved.\n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    @classmethod\n",
    "    def transform(cls, X) -> pd.DataFrame:\n",
    "        X = X.loc[(X[\"peakPower_W\"] != 0) & (\n",
    "            X[\"cumEnergy_Wh\"] != 0)].copy(deep=True)\n",
    "\n",
    "        X[\"connectTime\"] = pd.to_datetime(X[\"connectTime\"])\n",
    "        X[\"startChargeTime\"] = pd.to_datetime(X[\"startChargeTime\"])\n",
    "        X[\"Deadline\"] = pd.to_datetime(X[\"Deadline\"])\n",
    "        X[\"lastUpdate\"] = pd.to_datetime(X[\"lastUpdate\"])\n",
    "\n",
    "        X[\"finishChargeTime\"] = X.apply(cls.__get_finishChargeTime, axis=1)\n",
    "        X[\"trueDurationHrs\"] = X.apply(cls.__get_duration, axis=1)\n",
    "        X[\"true_peakPower_W\"] = X[\"cumEnergy_Wh\"] / X[\"trueDurationHrs\"]\n",
    "\n",
    "        # filter out bad rows (this occurs when there is a very low peak power and high energy delivered)\n",
    "        X = X.loc[X[\"trueDurationHrs\"] <= 24].copy()\n",
    "\n",
    "        X['temp_0'] = pd.Timedelta(days=0, seconds=0)\n",
    "        X['Overstay'] = X[\"lastUpdate\"] - X['Deadline']\n",
    "        X[\"Overstay\"] = X[[\"Overstay\", \"temp_0\"]].max(axis=1)\n",
    "        X['Overstay_h'] = X['Overstay'].dt.seconds / 3600\n",
    "\n",
    "        X.drop(columns=['temp_0'], inplace=True)\n",
    "\n",
    "        X.to_csv(\"data/raw_data.csv\")\n",
    "\n",
    "        return X\n",
    "    \n",
    "    @staticmethod\n",
    "    def __get_duration(row):\n",
    "        if row[\"regular\"] == 1:\n",
    "            return round(((row[\"lastUpdate\"] - row[\"startChargeTime\"]).seconds/3600), 3)\n",
    "        else: \n",
    "            return round(((row[\"Deadline\"] - row[\"startChargeTime\"]).seconds/3600), 3)\n",
    "        \n",
    "    @staticmethod\n",
    "    def __get_finishChargeTime(row):\n",
    "        if row[\"regular\"] == 1:\n",
    "            return row[\"lastUpdate\"]\n",
    "        else:\n",
    "            return row[\"Deadline\"]\n",
    "        \n",
    "\n",
    "class CreateSessionTimeSeries(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    This pipeline step will create a time series for each session. A dataframe\n",
    "    with 5-min granularity will be returned, with one column, \"power_demand_W\".\n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X) -> pd.DataFrame:\n",
    "        self.rows = []\n",
    "        X.apply(self.__create_ts, axis=1)\n",
    "        X = pd.concat(self.rows, axis=0).sort_index()\n",
    "        X = X.resample(\"5MIN\").sum()\n",
    "        return X\n",
    "\n",
    "    def __create_ts(self, session):\n",
    "        \"\"\"\n",
    "        This helper function takes in a session, with a \"connectTime\", \"finishChargeTime\", and \n",
    "        a \"peakPower_W\" column. Function will return a time series at 5-min granularity. \n",
    "        \"\"\"\n",
    "        date_range = pd.date_range(\n",
    "            start=session[\"startChargeTime\"], end=session[\"finishChargeTime\"], freq=\"5min\")\n",
    "        temp_df = pd.DataFrame(index=date_range)\n",
    "        temp_df[\"avg_power_demand_W\"] = session[\"true_peakPower_W\"]  # rename\n",
    "        self.rows.append(temp_df)\n",
    "\n",
    "\n",
    "class FeatureCreation(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    This pipeline step will create an \"energy_demand_kWh\" and \"peak_power_W\" column. \n",
    "    The name of the dataframe's index will be set to \"time\", and \"day\" and \"month\" columns \n",
    "    will be created. \n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    @ staticmethod\n",
    "    def transform(X) -> pd.DataFrame:\n",
    "        X[\"energy_demand_kWh\"] = (X[\"avg_power_demand_W\"]/1000)/12\n",
    "        # for the highest granularity, peak power is equal to the power demand\n",
    "        # (different for different granularities though)\n",
    "        X[\"peak_power_W\"] = X[\"avg_power_demand_W\"]\n",
    "        X.index.name = \"time\"\n",
    "        X[\"day\"] = X.index.day_name()\n",
    "        X[\"month\"] = X.index.month_name()\n",
    "        return X\n",
    "\n",
    "\n",
    "class SaveToCsv(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    This pipeline step takes each dataframe and creates new granularities\n",
    "    (hourly, daily, and monthly). Each dataframe is saved to a \"data/\" file. \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.agg_key = {\n",
    "            \"avg_power_demand_W\": \"mean\",\n",
    "            \"energy_demand_kWh\": \"sum\",\n",
    "            \"peak_power_W\": \"max\",\n",
    "            \"day\": \"first\",\n",
    "            \"month\": \"first\"\n",
    "        }\n",
    "        self.dataframe_names = [\n",
    "            \"fivemindemand\",\n",
    "            \"hourlydemand\",\n",
    "            \"dailydemand\",\n",
    "            \"monthlydemand\"\n",
    "        ]\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X) -> dict:\n",
    "        # create new granularities\n",
    "        hourlydemand = X.resample(\"1H\").agg(self.agg_key)\n",
    "        dailydemand = X.resample(\"24H\").agg(self.agg_key)\n",
    "        monthlydemand = X.resample(\"1M\").agg(self.agg_key)\n",
    "\n",
    "        new_dataframes = {\n",
    "            \"fivemindemand\": X,\n",
    "            \"hourlydemand\": hourlydemand,\n",
    "            \"dailydemand\": dailydemand,\n",
    "            \"monthlydemand\": monthlydemand\n",
    "        }\n",
    "\n",
    "        # save to file system\n",
    "        for idx, dataframe in enumerate(new_dataframes.values()):\n",
    "            dataframe.to_csv(f\"data/{self.dataframe_names[idx]}.csv\")\n",
    "        return new_dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38134100",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class HourlyForecast(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    columns = [\"avg_power_demand_W\", \"energy_demand_kWh\", \"peak_power_W\"]\n",
    "\n",
    "    def __init__(self, best_params: dict) -> None:\n",
    "        super().__init__()\n",
    "        self.best_params = best_params\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "\n",
    "        # add 24 hours to end of data \n",
    "        X = self.__create_24hrs_future(X)\n",
    "        # copy prediction interval\n",
    "        forecasts = pd.DataFrame(index=X.index[-24:])\n",
    "\n",
    "        for column in self.columns:\n",
    "            # get params\n",
    "            params = self.best_params.get(column)\n",
    "\n",
    "            # create regressor\n",
    "            regressor = KNeighborsRegressor(\n",
    "                n_neighbors=params[\"best_n_neighbors\"])\n",
    "            \n",
    "            # isolate column, create features\n",
    "            df = X[[column]].copy()\n",
    "            df = self.__create_lag_features(df,params[\"best_depth\"], col_name=column)\n",
    "\n",
    "            # split into training set and test set\n",
    "            X_train, X_test, y_train, y_test = self.__train_test_split(df, col_name=column)\n",
    "\n",
    "            # train regressor and predict 24 hours ahead\n",
    "            regressor.fit(X_train, y_train)\n",
    "            forecasts[column + \"_predictions\"] = regressor.predict(X_test).reshape(-1)\n",
    "\n",
    "        return forecasts\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def __create_24hrs_future(df):\n",
    "        prediction_range = pd.DataFrame(index=df.index[-24:] + pd.Timedelta(hours=24), columns=df.columns)\n",
    "        df = pd.concat([df, prediction_range])\n",
    "        return df \n",
    "\n",
    "    @staticmethod\n",
    "    def __create_lag_features(df, num_lag_depths, col_name):\n",
    "        df_with_lags = df.copy(deep=True)\n",
    "        for lag_depth in np.arange(1, num_lag_depths+1):\n",
    "            column = df_with_lags[col_name].shift(24*lag_depth)\n",
    "            df_with_lags = pd.concat([df_with_lags, column.rename(\"lag\" + f\"{lag_depth}\")], axis=1)\n",
    "        return df_with_lags.dropna(subset=df_with_lags.columns.drop(col_name)) # only rows with NaN as features, NaN in true value column is OK\n",
    "    \n",
    "    @staticmethod\n",
    "    def __train_test_split(df, col_name):\n",
    "        \"\"\"\n",
    "        Withhold the last 24 hours to predict the next 24 hours.\n",
    "        \"\"\"\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            df.drop(columns=col_name),\n",
    "            df[[col_name]],\n",
    "            test_size=24, # withhold last 24 hours\n",
    "            shuffle=False\n",
    "        )\n",
    "        return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b51065db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data...\n",
      "Cleaning data...\n",
      "Done!\n",
      "Fitting 1 folds for each of 336 candidates, totalling 336 fits\n",
      "Fitting 1 folds for each of 336 candidates, totalling 336 fits\n",
      "{'energy_demand_kWh': {'best_depth': 57, 'best_n_neighbors': 25}, 'peak_power_W': {'best_depth': 57, 'best_n_neighbors': 24}, 'avg_power_demand_W': {'best_depth': 57, 'best_n_neighbors': 25}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_params': {'energy_demand_kWh': {'best_depth': 57,\n",
       "   'best_n_neighbors': 25},\n",
       "  'peak_power_W': {'best_depth': 57, 'best_n_neighbors': 24},\n",
       "  'avg_power_demand_W': {'best_depth': 57, 'best_n_neighbors': 25}},\n",
       " 'last_validated_time': '04/02/23 17:36:38'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from app import update_ml_parameters\n",
    "\n",
    "best = update_ml_parameters()\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11db17be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_power_demand_W</th>\n",
       "      <th>energy_demand_kWh</th>\n",
       "      <th>peak_power_W</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-11-05 10:00:00</th>\n",
       "      <td>879.000000</td>\n",
       "      <td>0.439500</td>\n",
       "      <td>879.0</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>November</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-05 11:00:00</th>\n",
       "      <td>879.000000</td>\n",
       "      <td>0.879000</td>\n",
       "      <td>879.0</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>November</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-05 12:00:00</th>\n",
       "      <td>879.000000</td>\n",
       "      <td>0.879000</td>\n",
       "      <td>879.0</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>November</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-05 13:00:00</th>\n",
       "      <td>879.000000</td>\n",
       "      <td>0.879000</td>\n",
       "      <td>879.0</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>November</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-05 14:00:00</th>\n",
       "      <td>219.750000</td>\n",
       "      <td>0.219750</td>\n",
       "      <td>879.0</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>November</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-02 13:00:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>April</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-02 14:00:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>April</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-02 15:00:00</th>\n",
       "      <td>4984.166667</td>\n",
       "      <td>4.984167</td>\n",
       "      <td>5981.0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>April</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-02 16:00:00</th>\n",
       "      <td>5981.000000</td>\n",
       "      <td>5.981000</td>\n",
       "      <td>5981.0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>April</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-02 17:00:00</th>\n",
       "      <td>5981.000000</td>\n",
       "      <td>2.492083</td>\n",
       "      <td>5981.0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>April</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21080 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     avg_power_demand_W  energy_demand_kWh  peak_power_W  \\\n",
       "time                                                                       \n",
       "2020-11-05 10:00:00          879.000000           0.439500         879.0   \n",
       "2020-11-05 11:00:00          879.000000           0.879000         879.0   \n",
       "2020-11-05 12:00:00          879.000000           0.879000         879.0   \n",
       "2020-11-05 13:00:00          879.000000           0.879000         879.0   \n",
       "2020-11-05 14:00:00          219.750000           0.219750         879.0   \n",
       "...                                 ...                ...           ...   \n",
       "2023-04-02 13:00:00            0.000000           0.000000           0.0   \n",
       "2023-04-02 14:00:00            0.000000           0.000000           0.0   \n",
       "2023-04-02 15:00:00         4984.166667           4.984167        5981.0   \n",
       "2023-04-02 16:00:00         5981.000000           5.981000        5981.0   \n",
       "2023-04-02 17:00:00         5981.000000           2.492083        5981.0   \n",
       "\n",
       "                          day     month  \n",
       "time                                     \n",
       "2020-11-05 10:00:00  Thursday  November  \n",
       "2020-11-05 11:00:00  Thursday  November  \n",
       "2020-11-05 12:00:00  Thursday  November  \n",
       "2020-11-05 13:00:00  Thursday  November  \n",
       "2020-11-05 14:00:00  Thursday  November  \n",
       "...                       ...       ...  \n",
       "2023-04-02 13:00:00    Sunday     April  \n",
       "2023-04-02 14:00:00    Sunday     April  \n",
       "2023-04-02 15:00:00    Sunday     April  \n",
       "2023-04-02 16:00:00    Sunday     April  \n",
       "2023-04-02 17:00:00    Sunday     April  \n",
       "\n",
       "[21080 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = {'best_params': {'energy_demand_kWh': {'best_depth': 57,\n",
    "   'best_n_neighbors': 25},\n",
    "  'peak_power_W': {'best_depth': 57, 'best_n_neighbors': 24},\n",
    "  'avg_power_demand_W': {'best_depth': 57, 'best_n_neighbors': 25}},\n",
    " 'last_validated_time': '04/02/23 17:36:38'}\n",
    "df = pd.read_csv(\"data/hourlydemand.csv\", parse_dates=True, index_col=\"time\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d572035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_power_demand_W_predictions</th>\n",
       "      <th>energy_demand_kWh_predictions</th>\n",
       "      <th>peak_power_W_predictions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-04-02 18:00:00</th>\n",
       "      <td>724.366667</td>\n",
       "      <td>0.584810</td>\n",
       "      <td>1379.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-02 19:00:00</th>\n",
       "      <td>1091.010000</td>\n",
       "      <td>1.091010</td>\n",
       "      <td>782.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-02 20:00:00</th>\n",
       "      <td>1040.526667</td>\n",
       "      <td>1.040527</td>\n",
       "      <td>950.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-02 21:00:00</th>\n",
       "      <td>407.486667</td>\n",
       "      <td>0.407487</td>\n",
       "      <td>607.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-02 22:00:00</th>\n",
       "      <td>468.393333</td>\n",
       "      <td>0.468393</td>\n",
       "      <td>231.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-02 23:00:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-03 00:00:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-03 01:00:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-03 02:00:00</th>\n",
       "      <td>40.933333</td>\n",
       "      <td>0.040933</td>\n",
       "      <td>242.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-03 03:00:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>127.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-03 04:00:00</th>\n",
       "      <td>112.453333</td>\n",
       "      <td>0.112453</td>\n",
       "      <td>164.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-03 05:00:00</th>\n",
       "      <td>67.440000</td>\n",
       "      <td>0.030600</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-03 06:00:00</th>\n",
       "      <td>123.560000</td>\n",
       "      <td>0.123560</td>\n",
       "      <td>189.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-03 07:00:00</th>\n",
       "      <td>1880.586667</td>\n",
       "      <td>1.880587</td>\n",
       "      <td>2897.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-03 08:00:00</th>\n",
       "      <td>6729.503333</td>\n",
       "      <td>6.729503</td>\n",
       "      <td>11052.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-03 09:00:00</th>\n",
       "      <td>12151.313333</td>\n",
       "      <td>12.151313</td>\n",
       "      <td>12906.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-03 10:00:00</th>\n",
       "      <td>14076.006667</td>\n",
       "      <td>14.076007</td>\n",
       "      <td>16027.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-03 11:00:00</th>\n",
       "      <td>14990.596667</td>\n",
       "      <td>14.990597</td>\n",
       "      <td>15531.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-03 12:00:00</th>\n",
       "      <td>13805.190000</td>\n",
       "      <td>13.805190</td>\n",
       "      <td>15614.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-03 13:00:00</th>\n",
       "      <td>11959.596667</td>\n",
       "      <td>11.959597</td>\n",
       "      <td>12220.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-03 14:00:00</th>\n",
       "      <td>8690.336667</td>\n",
       "      <td>8.690337</td>\n",
       "      <td>5983.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-03 15:00:00</th>\n",
       "      <td>7208.113333</td>\n",
       "      <td>7.208113</td>\n",
       "      <td>10369.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-03 16:00:00</th>\n",
       "      <td>6942.323333</td>\n",
       "      <td>6.942323</td>\n",
       "      <td>8484.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-03 17:00:00</th>\n",
       "      <td>4773.613333</td>\n",
       "      <td>4.550787</td>\n",
       "      <td>7892.583333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     avg_power_demand_W_predictions  \\\n",
       "time                                                  \n",
       "2023-04-02 18:00:00                      724.366667   \n",
       "2023-04-02 19:00:00                     1091.010000   \n",
       "2023-04-02 20:00:00                     1040.526667   \n",
       "2023-04-02 21:00:00                      407.486667   \n",
       "2023-04-02 22:00:00                      468.393333   \n",
       "2023-04-02 23:00:00                        0.000000   \n",
       "2023-04-03 00:00:00                        0.000000   \n",
       "2023-04-03 01:00:00                        0.000000   \n",
       "2023-04-03 02:00:00                       40.933333   \n",
       "2023-04-03 03:00:00                        0.000000   \n",
       "2023-04-03 04:00:00                      112.453333   \n",
       "2023-04-03 05:00:00                       67.440000   \n",
       "2023-04-03 06:00:00                      123.560000   \n",
       "2023-04-03 07:00:00                     1880.586667   \n",
       "2023-04-03 08:00:00                     6729.503333   \n",
       "2023-04-03 09:00:00                    12151.313333   \n",
       "2023-04-03 10:00:00                    14076.006667   \n",
       "2023-04-03 11:00:00                    14990.596667   \n",
       "2023-04-03 12:00:00                    13805.190000   \n",
       "2023-04-03 13:00:00                    11959.596667   \n",
       "2023-04-03 14:00:00                     8690.336667   \n",
       "2023-04-03 15:00:00                     7208.113333   \n",
       "2023-04-03 16:00:00                     6942.323333   \n",
       "2023-04-03 17:00:00                     4773.613333   \n",
       "\n",
       "                     energy_demand_kWh_predictions  peak_power_W_predictions  \n",
       "time                                                                          \n",
       "2023-04-02 18:00:00                       0.584810               1379.041667  \n",
       "2023-04-02 19:00:00                       1.091010                782.000000  \n",
       "2023-04-02 20:00:00                       1.040527                950.833333  \n",
       "2023-04-02 21:00:00                       0.407487                607.958333  \n",
       "2023-04-02 22:00:00                       0.468393                231.375000  \n",
       "2023-04-02 23:00:00                       0.000000                  9.958333  \n",
       "2023-04-03 00:00:00                       0.000000                  0.000000  \n",
       "2023-04-03 01:00:00                       0.000000                  0.000000  \n",
       "2023-04-03 02:00:00                       0.040933                242.916667  \n",
       "2023-04-03 03:00:00                       0.000000                127.916667  \n",
       "2023-04-03 04:00:00                       0.112453                164.166667  \n",
       "2023-04-03 05:00:00                       0.030600                  0.000000  \n",
       "2023-04-03 06:00:00                       0.123560                189.750000  \n",
       "2023-04-03 07:00:00                       1.880587               2897.666667  \n",
       "2023-04-03 08:00:00                       6.729503              11052.458333  \n",
       "2023-04-03 09:00:00                      12.151313              12906.250000  \n",
       "2023-04-03 10:00:00                      14.076007              16027.875000  \n",
       "2023-04-03 11:00:00                      14.990597              15531.375000  \n",
       "2023-04-03 12:00:00                      13.805190              15614.500000  \n",
       "2023-04-03 13:00:00                      11.959597              12220.375000  \n",
       "2023-04-03 14:00:00                       8.690337               5983.500000  \n",
       "2023-04-03 15:00:00                       7.208113              10369.875000  \n",
       "2023-04-03 16:00:00                       6.942323               8484.041667  \n",
       "2023-04-03 17:00:00                       4.550787               7892.583333  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"estimator\", HourlyForecast(best_params=best[\"best_params\"]))\n",
    "])\n",
    "\n",
    "forecasts = pipeline.fit_transform(df)\n",
    "forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea0d6be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "475dd3d8de922d6629668699edf7da91807dd0e731d2ca4abf0ed1b52cb8d54e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
